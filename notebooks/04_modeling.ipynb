{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f07422ac",
   "metadata": {},
   "source": [
    "# 1. Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from models.logistic_regression import LogisticRegression\n",
    "from models.random_forest import RandomForest\n",
    "from evaluator.evaluator import Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35664190",
   "metadata": {},
   "source": [
    "# 2. Các hằng số cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "DATA_DIR = Path(\"../data\")\n",
    "FINAL_DATA_DIR = DATA_DIR / \"final\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2bae5",
   "metadata": {},
   "source": [
    "# 3. Load các tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e9fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: Path):\n",
    "    \"\"\"\n",
    "    Load preprocessed training and testing data from specified directory.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_path : Path\n",
    "        Directory containing the numpy arrays\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (X_train, y_train, X_test, y_test)\n",
    "        Training and testing features and labels\n",
    "    \"\"\"\n",
    "    X_train = np.load(file_path / \"X_train.npy\")\n",
    "    y_train = np.load(file_path / \"y_train.npy\")\n",
    "    X_test = np.load(file_path / \"X_test.npy\")\n",
    "    y_test = np.load(file_path / \"y_test.npy\")\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "# Dữ liệu gốc chưa xử lý cân bằng\n",
    "original_X_train, original_y_train, original_X_test, original_y_test = load_data(\n",
    "    FINAL_DATA_DIR / \"original\"\n",
    ")\n",
    "\n",
    "# Dữ liệu sau khi giảm mẫu (under-sampled)\n",
    "under_sample_X_train, under_sample_y_train, under_sample_X_test, under_sample_y_test = (\n",
    "    load_data(FINAL_DATA_DIR / \"under_sampled\")\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Original dataset shapes:\")\n",
    "print(f\"  Training: X={original_X_train.shape}, y={original_y_train.shape}\")\n",
    "print(f\"  Testing:  X={original_X_test.shape}, y={original_y_test.shape}\")\n",
    "print(f\"\\nUnder-sampled dataset shapes:\")\n",
    "print(f\"  Training: X={under_sample_X_train.shape}, y={under_sample_y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d42291",
   "metadata": {},
   "source": [
    "# 4. Metrics đánh giá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef89914",
   "metadata": {},
   "source": [
    "Các thang đo sẽ được sử dụng trong việc đánh giá mô hình:\n",
    "\n",
    "- **Accuracy**: Mức độ chính xác tổng thể của mô hình.\n",
    "- **Precision**: Tỷ lệ dự đoán dương tính đúng trên tổng số dự đoán dương tính (giảm cảnh báo giả).\n",
    "- **Recall**: Tỷ lệ dự đoán dương tính đúng trên tổng số mẫu dương tính thực sự (quan trọng khi cần phát hiện gian lận).\n",
    "- **F1-Score**: Trung bình điều hòa giữa Precision và Recall.\n",
    "- **PR-AUC**: Diện tích dưới đường cong Precision–Recall (đặc biệt phù hợp cho tập dữ liệu mất cân bằng).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a01320",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\", \"pr_auc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502589c",
   "metadata": {},
   "source": [
    "# 5. Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78409b",
   "metadata": {},
   "source": [
    "- Ta sẽ thực hiện việc đánh giá trên tập dữ liệu gốc chủ yếu trên mô hình đã được huấn luyện trên tập dữ liệu under-sampled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdacb1d",
   "metadata": {},
   "source": [
    "## 5.1 Mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8549ef7",
   "metadata": {},
   "source": [
    "Mô hình Logistic Regression là một mô hình phân loại tuyến tính, ước lượng xác suất gian lận thông qua hàm sigmoid. Mặc dù đơn giản, logistic regression thường mang lại hiệu suất cơ sở mạnh mẽ cho các bài toán phân loại nhị phân.\n",
    "\n",
    "**Hyperparameters:**\n",
    "- Learning rate: 0.01  \n",
    "- Số vòng lặp (iterations): 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(\n",
    "    learning_rate=0.01,\n",
    "    n_iterations=1000,\n",
    ")\n",
    "\n",
    "print(\"Huấn luyện Logistic Regression trên tập dữ liệu giảm mẫu...\")\n",
    "lr_model.fit(under_sample_X_train, under_sample_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637ed6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_under_pred = lr_model.predict(under_sample_X_test)\n",
    "\n",
    "print(\"-- Logistic Regression Performance (Under-sampled Test Set) --\")\n",
    "lr_under_results = evaluator.evaluate(\n",
    "    y_true=under_sample_y_test,\n",
    "    y_pred=lr_under_pred,\n",
    "    visualize=True,\n",
    ")\n",
    "\n",
    "lr_original_pred = lr_model.predict(original_X_test)\n",
    "\n",
    "print(\"-- Logistic Regression Performance (Original Imbalanced Test Set) --\")\n",
    "lr_original_results = evaluator.evaluate(\n",
    "    y_true=original_y_test,\n",
    "    y_pred=lr_original_pred,\n",
    "    visualize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8714e",
   "metadata": {},
   "source": [
    "### Nhận xét\n",
    "- Trên tập dữ liệu giảm mẫu:\n",
    "    - Các chỉ số đều cao và cân bằng, đặc biệt là precision (~0.97) và recall (~0.91).\n",
    "    - Điều này cho thấy khi dữ liệu được under-sampling để trở nên cân bằng, mô hình học ranh giới phân lớp rất tốt.\n",
    "    - PR-AUC cao (~0.96) chứng minh mô hình vẫn giữ hiệu suất ổn ngay cả khi threshold thay đổi.\n",
    "- Trên tập dữ liệu mất cân bằng gốc:\n",
    "    - Accuracy nhìn cao (~0.95) nhưng vô nghĩa trong bài toán bị mất cân bằng.\n",
    "    - Precision cực thấp (~0.03) → trong số các mẫu bị dự đoán là gian lận, chỉ 3% là thật.\n",
    "    - Recall cao (~0.94) → mô hình hầu như bắt được toàn bộ các mẫu gian lận.\n",
    "    - F1-score rất thấp (~0.06) → mất cân bằng nghiêm trọng giữa precision và recall.\n",
    "    - PR-AUC (0.48) < 0.5 → mô hình gần như không tốt hơn random khi đánh đổi giữa precision–recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec603e",
   "metadata": {},
   "source": [
    "### Dự đoán\n",
    "Do dữ liệu thật rất mất cân bằng, logistic regression nghiêng về việc dự đoán tất cả là “gian lận” để tối ưu recall → nhưng dẫn đến precision thấp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d1cdfd",
   "metadata": {},
   "source": [
    "## 5.2 Mô hình Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55919991",
   "metadata": {},
   "source": [
    "Random Forest là một phương pháp học ensemble, xây dựng nhiều cây quyết định trong giai đoạn huấn luyện và đưa ra dự đoán dựa trên kết quả biểu quyết của các cây. Mô hình đặc biệt hiệu quả trong việc xử lý các quan hệ phi tuyến và tương tác giữa các đặc trưng.\n",
    "\n",
    "**Ưu điểm chính trong bài toán phát hiện gian lận:**\n",
    "- Xử lý tốt các quan hệ phi tuyến trong dữ liệu  \n",
    "- Mạnh mẽ trước nhiễu và các điểm ngoại lai  \n",
    "- Tự động cung cấp mức độ quan trọng của đặc trưng \n",
    "- Giảm overfitting nhờ cơ chế lấy trung bình từ nhiều cây"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9709d",
   "metadata": {},
   "source": [
    "### 5.2.1 Tham số gốc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e08480",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_baseline = RandomForest(\n",
    "    n_trees=10,\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Huấn luyện Random Forest trên tập dữ liệu giảm mẫu...\")\n",
    "rf_baseline.fit(under_sample_X_train, under_sample_y_train),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f01a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_under_pred = rf_baseline.predict(under_sample_X_test)\n",
    "\n",
    "print(\"\\n-- Random Forest Baseline Performance (Under-sampled Test Set) --\")\n",
    "rf_under_results = evaluator.evaluate(\n",
    "    y_true=under_sample_y_test,\n",
    "    y_pred=rf_under_pred,\n",
    "    visualize=True,\n",
    ")\n",
    "\n",
    "rf_baseline_pred = rf_baseline.predict(original_X_test)\n",
    "\n",
    "print(\"-- Random Forest Baseline Performance (Original Imbalanced Test Set) --\")\n",
    "rf_baseline_results = evaluator.evaluate(\n",
    "    y_true=original_y_test,\n",
    "    y_pred=rf_baseline_pred,\n",
    "    visualize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b1ce6",
   "metadata": {},
   "source": [
    "### Nhận xét\n",
    "- Tương tự với Logistic Regression, Random Forest cũng đạt hiệu suất rất tốt trên tập dữ liệu đã được under-sampling, với các chỉ số precision, recall, F1 và PR-AUC đều cao và cân bằng. Điều này cho thấy mô hình hoạt động ổn khi phân phối dữ liệu được làm cân bằng nhân tạo.\n",
    "- Tuy nhiên, khi đánh giá trên tập dữ liệu gốc vốn rất mất cân bằng, hiệu suất giảm mạnh — đặc biệt là precision thấp và PR-AUC chỉ khoảng 0.497, gần mức random. Điều này chứng tỏ mô hình không tổng quát tốt trên phân phối thật và tiếp tục gặp khó khăn trong việc xử lý thiên lệch lớp nặng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d781da1",
   "metadata": {},
   "source": [
    "### 5.2.2 Tham số lớn hơn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed84195",
   "metadata": {},
   "source": [
    "Dựa trên tham số gốc, ta sẽ thực hiện việc điều chỉnh tham số để kiểm tra kết quả:\n",
    "- Tăng số lượng cây.\n",
    "- Tăng chiều sâu tối đa. \\\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ce7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_optimized = RandomForest(\n",
    "    n_trees=50,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_features=\"sqrt\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "print(\"Huấn luyện Random Forest tối ưu trên tập dữ liệu giảm mẫu...\")\n",
    "rf_optimized.fit(under_sample_X_train, under_sample_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_opt_under_pred = rf_optimized.predict(under_sample_X_test)\n",
    "print(\"\\n-- Optimized Random Forest Performance (Under-sampled Test Set) --\")\n",
    "rf_opt_under_results = evaluator.evaluate(\n",
    "    y_true=under_sample_y_test,\n",
    "    y_pred=rf_opt_under_pred,\n",
    "    visualize=True,\n",
    ")\n",
    "\n",
    "\n",
    "rf_opt_pred = rf_optimized.predict(original_X_test)\n",
    "\n",
    "print(\"\\n-- Optimized Random Forest Performance (Original Imbalanced Test Set) --\")\n",
    "rf_opt_results = evaluator.evaluate(\n",
    "    y_true=original_y_test,\n",
    "    y_pred=rf_opt_pred,\n",
    "    visualize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21efcf40",
   "metadata": {},
   "source": [
    "### Nhận xét\n",
    "- Mô hình Random Forest sau khi tăng số lượng cây (và các tham số khác) tiếp tục đạt hiệu suất rất tốt trên tập dữ liệu đã được under-sampling, với precision gần như tuyệt đối (0.9929), F1-score cao và PR-AUC đạt 0.9718. Điều này cho thấy mô hình có khả năng học biên phân lớp trong môi trường cân bằng một cách mạnh mẽ hơn so với phiên bản ban đầu.\n",
    "- Tuy nhiên, khi đánh giá trên tập dữ liệu gốc vốn mất cân bằng, hiệu suất vẫn giảm đáng kể. Precision chỉ còn 0.0823 và F1-score 0.1516 — tốt hơn so với Random Forest gốc nhưng vẫn không đạt mức chấp nhận được cho bài toán fraud detection. PR-AUC cải thiện lên 0.5191, nhỉnh hơn một chút so với 0.4970 trước đó, nhưng vẫn chỉ ở mức vừa đủ và chưa tạo ra khác biệt đáng kể."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dd3003",
   "metadata": {},
   "source": [
    "# 6. Vấn đề gặp phải"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d008de7",
   "metadata": {},
   "source": [
    "- Dữ liệu cực kỳ mất cân bằng chưa được xử lý đầy đủ: việc chỉ áp dụng giảm mẫu làm giảm đáng kể dữ liệu lớp đa số, dẫn đến mất thông tin và khiến mô hình khó tổng quát hóa trên phân phối thật.\n",
    "- Chưa thử nghiệm các kỹ thuật xử lý mất cân bằng tiên tiến: các phương pháp như SMOTE, ADASYN, ... chưa được triển khai, hạn chế khả năng cải thiện kết quả trên các thang đo.\n",
    "- Chỉ mới thực hiện đánh giá trên mô hình tuyến tính và cây quyết định: có những mô hình mạnh hơn, chuyên biệt cho bài toán với dữ liệu mất cân bằng (XGBoost, LightBGM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abb180",
   "metadata": {},
   "source": [
    "# 7. Tổng kết"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331af4b7",
   "metadata": {},
   "source": [
    "- Trong bài báo cáo này, ta thấy được hiệu suất của ba mô hình học máy—Logistic Regression, Random Forest và Optimized Random Forest—trên bài toán phát hiện gian lận với một tập dữ liệu có mức mất cân bằng nghiêm trọng. Kết quả thực nghiệm cho thấy under-sampling mang đến các chỉ số đánh giá rất cao trên tập dữ liệu cân bằng, nhưng những kết quả này không phản ánh đúng khả năng tổng quát hóa của mô hình trên phân phối dữ liệu thật.\n",
    "- Trên tập dữ liệu gốc, cả Logistic Regression và Random Forest đều đạt accuracy cao nhưng precision rất thấp, dẫn đến F1-score thấp và hiệu suất tổng thể không phù hợp cho nhiệm vụ phát hiện gian lận. Mặc dù Random Forest sau khi tối ưu (tăng số lượng cây và điều chỉnh tham số) cho thấy sự cải thiện nhỏ — thể hiện qua việc PR-AUC tăng từ ~0.4970 lên ~0.5191 — mức cải thiện này vẫn không đủ để mô hình trở nên khả dụng trong thực tế. Điều này khẳng định rằng tăng độ phức tạp mô hình không giải quyết được căn nguyên của vấn đề, đó là sự mất cân bằng nghiêm trọng của dữ liệu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
